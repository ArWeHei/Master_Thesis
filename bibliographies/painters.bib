@article{neuralpainters, 
author = {Nakano, Reiichiro}, 
title = {{Neural Painters: A learned differentiable constraint for generating brushstroke paintings}}, 
eprint = {1904.08410}, 
abstract = {{We explore neural painters, a generative model for brushstrokes learned from a real non-differentiable and non-deterministic painting program. We show that when training an agent to "paint" images using brushstrokes, using a differentiable neural painter leads to much faster convergence. We propose a method for encouraging this agent to follow human-like strokes when reconstructing digits. We also explore the use of a neural painter as a differentiable image parameterization. By directly optimizing brushstrokes to activate neurons in a pre-trained convolutional network, we can directly visualize ImageNet categories and generate "ideal" paintings of each class. Finally, we present a new concept called intrinsic style transfer. By minimizing only the content loss from neural style transfer, we allow the artistic medium, in this case, brushstrokes, to naturally dictate the resulting style.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1904.08410.pdf_Unknown_Unknown.pdf}, 
year = {2019}, 
rating = {4}
}
@article{graves, 
author = {Graves, Alex}, 
title = {{Generating Sequences With Recurrent Neural Networks}}, 
eprint = {1308.0850}, 
abstract = {{This paper shows how Long Short-term Memory recurrent neural networks can be used to generate complex sequences with long-range structure, simply by predicting one data point at a time. The approach is demonstrated for text (where the data are discrete) and online handwriting (where the data are real-valued). It is then extended to handwriting synthesis by allowing the network to condition its predictions on a text sequence. The resulting system is able to generate highly realistic cursive handwriting in a wide variety of styles.}}, 
journal = {arXiv}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/2013_Generating%20Sequences%20With%20Recurrent%20Neural%20Networks_Graves_Graves.pdf}, 
year = {2013}
}
@article{sketchRNN, 
author = {Ha, David and Eck, Douglas}, 
title = {{A Neural Representation of Sketch Drawings}}, 
eprint = {1704.03477}, 
abstract = {{We present sketch-rnn, a recurrent neural network (RNN) able to construct stroke-based drawings of common objects. The model is trained on thousands of crude human-drawn images representing hundreds of classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.}}, 
journal = {arXiv}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/2017_A%20Neural%20Representation%20of%20Sketch%20Drawings_Ha_Eck.pdf}, 
year = {2017}
}
@article{paintbot, 
author = {Jia, Biao and Fang, Chen and Brandt, Jonathan and Kim, Byungmoon and Manocha, Dinesh}, 
title = {{PaintBot: A Reinforcement Learning Approach for Natural Media Painting}}, 
eprint = {1904.02201}, 
abstract = {{We propose a new automated digital painting framework, based on a painting agent trained through reinforcement learning. To synthesize an image, the agent selects a sequence of continuous-valued actions representing primitive painting strokes, which are accumulated on a digital canvas. Action selection is guided by a given reference image, which the agent attempts to replicate subject to the limitations of the action space and the agent's learned policy. The painting agent policy is determined using a variant of proximal policy optimization reinforcement learning. During training, our agent is presented with patches sampled from an ensemble of reference images. To accelerate training convergence, we adopt a curriculum learning strategy, whereby reference patches are sampled according to how challenging they are using the current policy. We experiment with differing loss functions, including pixel-wise and perceptual loss, which have consequent differing effects on the learned policy. We demonstrate that our painting agent can learn an effective policy with a high dimensional continuous action space comprising pen pressure, width, tilt, and color, for a variety of painting styles. Through a coarse-to-fine refinement process our agent can paint arbitrarily complex images in the desired style.}}, 
journal = {arXiv}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/2019_PaintBot-%20A%20Reinforcement%20Learning%20Approach%20for%20Natural%20Media%20Painting_Jia_Manocha.pdf}, 
year = {2019}
}
@article{undefined, 
author = {Zhao, Amy and Balakrishnan, Guha and Lewis, Kathleen M and Durand, Fr√©do and Guttag, John V and Dalca, Adrian V}, 
title = {{Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings}}, 
eprint = {2001.01026}, 
abstract = {{We introduce a new video synthesis task: synthesizing time lapse videos depicting how a given painting might have been created. Artists paint using unique combinations of brushes, strokes, and colors. There are often many possible ways to create a given painting. Our goal is to learn to capture this rich range of possibilities. Creating distributions of long-term videos is a challenge for learning-based video synthesis methods. We present a probabilistic model that, given a single image of a completed painting, recurrently synthesizes steps of the painting process. We implement this model as a convolutional neural network, and introduce a novel training scheme to enable learning from a limited dataset of painting time lapses. We demonstrate that this model can be used to sample many time steps, enabling long-term stochastic video synthesis. We evaluate our method on digital and watercolor paintings collected from video websites, and show that human raters find our synthetic videos to be similar to time lapse videos produced by real artists. Our code is available at https://xamyzhao.github.io/timecraft.}}, 
journal = {arXiv}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_2001.01026.pdf_Unknown_Unknown.pdf}, 
year = {2020}
}
@article{strokenet, 
author = {Zheng, Ningyuan and Jiang, Yifan and Huang, Dingjiang}, 
title = {{Strokenet: A neural painting environment}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/2019_Strokenet-%20A%20neural%20painting%20environment_Zheng_Huang.pdf}, 
year = {2019}, 
rating = {3}
}
@article{SPIRAL, 
author = {Ganin, Yaroslav and Kulkarni, Tejas and Babuschkin, Igor and Eslami, S M Ali and Vinyals, Oriol}, 
title = {{Synthesizing Programs for Images using Reinforced Adversarial Learning}}, 
eprint = {1804.01118}, 
abstract = {{Advances in deep generative networks have led to impressive results in recent years. Nevertheless, such models can often waste their capacity on the minutiae of datasets, presumably due to weak inductive biases in their decoders. This is where graphics engines may come in handy since they abstract away low-level details and represent images as high-level programs. Current methods that combine deep learning and renderers are limited by hand-crafted likelihood or distance functions, a need for large amounts of supervision, or difficulties in scaling their inference algorithms to richer datasets. To mitigate these issues, we present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images. The goal of this agent is to fool a discriminator network that distinguishes between real and rendered data, trained with a distributed reinforcement learning setup without any supervision. A surprising finding is that using the discriminator's output as a reward signal is the key to allow the agent to make meaningful progress at matching the desired output rendering. To the best of our knowledge, this is the first demonstration of an end-to-end, unsupervised and adversarial inverse graphics agent on challenging real world (MNIST, Omniglot, CelebA) and synthetic 3D datasets.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1804.01118.pdf_Unknown_Unknown.pdf}, 
year = {2018}, 
rating = {4}
}
@article{LpaintB, 
author = {Jia, Biao and Brandt, Jonathan and Mech, Radomir and Kim, Byungmoon and Manocha, Dinesh}, 
title = {{LPaintB: Learning to Paint from Self-Supervision}}, 
eprint = {1906.06841}, 
abstract = {{We present a novel reinforcement learning-based natural media painting algorithm. Our goal is to reproduce a reference image using brush strokes and we encode the objective through observations. Our formulation takes into account that the distribution of the reward in the action space is sparse and training a reinforcement learning algorithm from scratch can be difficult. We present an approach that combines self-supervised learning and reinforcement learning to effectively transfer negative samples into positive ones and change the reward distribution. We demonstrate the benefits of our painting agent to reproduce reference images with brush strokes. The training phase takes about one hour and the runtime algorithm takes about 30 seconds on a GTX1080 GPU reproducing a 1000x800 image with 20,000 strokes.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1906.06841.pdf_Unknown_Unknown.pdf}, 
year = {2019}
}
@article{learning2paint, 
author = {Huang, Zhewei and Heng, Wen and Zhou, Shuchang}, 
title = {{Learning to Paint With Model-based Deep Reinforcement Learning}}, 
eprint = {1903.04411}, 
abstract = {{We show how to teach machines to paint like human painters, who can use a small number of strokes to create fantastic paintings. By employing a neural renderer in model-based Deep Reinforcement Learning (DRL), our agents learn to determine the position and color of each stroke and make long-term plans to decompose texture-rich images into strokes. Experiments demonstrate that excellent visual effects can be achieved using hundreds of strokes. The training process does not require the experience of human painters or stroke tracking data. The code is available at https://github.com/hzwer/ICCV2019-LearningToPaint.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1903.04411.pdf_Unknown_Unknown.pdf}, 
year = {2019}, 
rating = {3}
}