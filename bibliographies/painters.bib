@article{Learning2Paint, 
author = {Huang, Zhewei and Heng, Wen and Zhou, Shuchang}, 
title = {{Learning to Paint With Model-based Deep Reinforcement Learning}}, 
eprint = {1903.04411}, 
abstract = {{We show how to teach machines to paint like human painters, who can use a small number of strokes to create fantastic paintings. By employing a neural renderer in model-based Deep Reinforcement Learning (DRL), our agents learn to determine the position and color of each stroke and make long-term plans to decompose texture-rich images into strokes. Experiments demonstrate that excellent visual effects can be achieved using hundreds of strokes. The training process does not require the experience of human painters or stroke tracking data. The code is available at https://github.com/hzwer/ICCV2019-LearningToPaint.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1903.04411.pdf_Unknown_Unknown.pdf}, 
year = {2019}, 
rating = {3}
}
@article{NeuralPainters, 
author = {Nakano, Reiichiro}, 
title = {{Neural Painters: A learned differentiable constraint for generating brushstroke paintings}}, 
eprint = {1904.08410}, 
abstract = {{We explore neural painters, a generative model for brushstrokes learned from a real non-differentiable and non-deterministic painting program. We show that when training an agent to "paint" images using brushstrokes, using a differentiable neural painter leads to much faster convergence. We propose a method for encouraging this agent to follow human-like strokes when reconstructing digits. We also explore the use of a neural painter as a differentiable image parameterization. By directly optimizing brushstrokes to activate neurons in a pre-trained convolutional network, we can directly visualize ImageNet categories and generate "ideal" paintings of each class. Finally, we present a new concept called intrinsic style transfer. By minimizing only the content loss from neural style transfer, we allow the artistic medium, in this case, brushstrokes, to naturally dictate the resulting style.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1904.08410.pdf_Unknown_Unknown.pdf}, 
year = {2019}, 
rating = {4}
}
@article{LPaintB, 
author = {Jia, Biao and Brandt, Jonathan and Mech, Radomir and Kim, Byungmoon and Manocha, Dinesh}, 
title = {{LPaintB: Learning to Paint from Self-Supervision}}, 
eprint = {1906.06841}, 
abstract = {{We present a novel reinforcement learning-based natural media painting algorithm. Our goal is to reproduce a reference image using brush strokes and we encode the objective through observations. Our formulation takes into account that the distribution of the reward in the action space is sparse and training a reinforcement learning algorithm from scratch can be difficult. We present an approach that combines self-supervised learning and reinforcement learning to effectively transfer negative samples into positive ones and change the reward distribution. We demonstrate the benefits of our painting agent to reproduce reference images with brush strokes. The training phase takes about one hour and the runtime algorithm takes about 30 seconds on a GTX1080 GPU reproducing a 1000x800 image with 20,000 strokes.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1906.06841.pdf_Unknown_Unknown.pdf}, 
year = {2019}
}
@article{SPIRAL, 
author = {Ganin, Yaroslav and Kulkarni, Tejas and Babuschkin, Igor and Eslami, S M Ali and Vinyals, Oriol}, 
title = {{Synthesizing Programs for Images using Reinforced Adversarial Learning}}, 
eprint = {1804.01118}, 
abstract = {{Advances in deep generative networks have led to impressive results in recent years. Nevertheless, such models can often waste their capacity on the minutiae of datasets, presumably due to weak inductive biases in their decoders. This is where graphics engines may come in handy since they abstract away low-level details and represent images as high-level programs. Current methods that combine deep learning and renderers are limited by hand-crafted likelihood or distance functions, a need for large amounts of supervision, or difficulties in scaling their inference algorithms to richer datasets. To mitigate these issues, we present SPIRAL, an adversarially trained agent that generates a program which is executed by a graphics engine to interpret and sample images. The goal of this agent is to fool a discriminator network that distinguishes between real and rendered data, trained with a distributed reinforcement learning setup without any supervision. A surprising finding is that using the discriminator's output as a reward signal is the key to allow the agent to make meaningful progress at matching the desired output rendering. To the best of our knowledge, this is the first demonstration of an end-to-end, unsupervised and adversarial inverse graphics agent on challenging real world (MNIST, Omniglot, CelebA) and synthetic 3D datasets.}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/Unknown_1804.01118.pdf_Unknown_Unknown.pdf}, 
year = {2018}, 
rating = {4}
}
@article{StrokeNet, 
author = {Zheng, Ningyuan and Jiang, Yifan and Huang, Dingjiang}, 
title = {{StrokeNet: A Neural Painting Environment}}, 
local-url = {file://localhost/Users/arthur/Documents/Papers%20Library/strokenet_a_neural_painting_environment.pdf}, 
rating = {3}
}