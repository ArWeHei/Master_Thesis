\setchapterpreamble[u]{\margintoc}
\chapter{Discussion}
\labch{Discussion}

This thesis's original goal was to come up with a feed-forward architecture, which can predict brushstrokes in a painting.
This architecture should be built around a differentiable renderer, which renders brushstrokes from parameters.
Such an approach would have two use-cases:
\begin{enumerate}
    \item Generate 'brushstroke representations' of input paintings, which describes paintings as brushstrokes instead of pixels.
    \item Render images as paintings if the input is a photograph.
\end{enumerate}

Especially the aspiration of achieving this with a single feed-forward approach has been proven difficult.
For once, existing approaches either restrict themselves to very low image resolutions or iteratively predict brushstrokes.
As both these compromises ought to be avoided, an orthogonal approach has been chosen.
This approach places many brushstrokes on a virtual canvas.
Then the brushstroke parameters are iteratively optimized through backpropagation.
It was possible to show that a target image with a resolution of $\approx 1$ megapixel can be approximated with such a set-up.

Nevertheless, this approach features some weaknesses.
First of all, it takes approximately one hour per image to obtain a brushstroke representation.
Then, the approach struggles with large uniformly colored regions in images.
The best approximations could be gathered if single brushstrokes are visible and set themselves apart from the background.
Furthermore, the optimization requires many constraints, and lots of compromises are necessary to keep the computational burden low.
The limited data set with only a single control-point, which was used to train the renderer, is a good example of this.

Still, the results could be compared to what others have previously achieved.
The closest approaches to this thesis are those by \citeauthor*{LpaintB} and \citeauthor*{neuralpainters}.\\
\citeauthor*{LpaintB} were able to recreate a painting by sliding a window over it for which brushstrokes are predicted in a feed-forward manner.
The network is trained explicitly for a single image and shows style transfer-like behavior if applied to other images.
It takes about an hour to train the network per 1 MP image, as the author claim.\\
\citeauthor*{neuralpainters} focused his work on training a recurrent approach to predict brushstrokes.
However, he showed a first approach which recreated content in an image by optimizing the brushstroke parameters directly.\\
Both approaches presented a differentiable renderer as a key-element, much like this thesis.

Compared to both of these approaches, this thesis put more effort into building a suitable renderer.
It seems to have paid off when looking at the details in the image.
Brushstrokes show fading and narrowing towards their ends which lines up with real-world observations.\\
When rendering images of van Gogh paintings, it seems as if a majority of brushstrokes aligns with the 'flow' of the original painting.
Especially brushstrokes in 'The Starry Night would follow the curly flow, which can be seen in the original.
Compared to \citeauthor*{LpaintB} the visual quality seems to have improved while a similar amount of time is necessary to approximate a single painting.\\
When considering the stylization of photos, this thesis could only offer a single oil painting-like style.
\citeauthor*{LpaintB} offer more styles (\eg watercolor).
Comparing stylizations is highly subjective.
Thus, readers are encouraged to look at the provided stylizations of the same image and build their verdict (see \reffig{final_stylization}).
A noteworthy aspect is how well this thesis' approach aligns brushstrokes with edges in the stylization, much like artists presumably would choose to do.

\citeauthor*{neuralpainters} presented a stylization approach very close to the approach of this thesis.
Arguably, it comes up with a very nice level of abstraction.
As this thesis focused harder on being closer to the original image, these two approaches are hard to compare.
Nonetheless, it would be desirable to achieve similar levels of abstraction by tweaking the approach of this thesis.


Another comparison has was made to brushstroke extraction.
\citeauthor*{lamberti} presented an approach aimed specifically at extracting brushstroke properties from painting images.
This thesis also aimed at extracting brushstrokes from images.
Up until now, there has not been a known neural network-based approach to do so.
Comparisons showed that \citeauthor*{lamberti} were able to extract single brushstrokes more precisely.
Still, the rendering based approach of this thesis was able to cover the whole image area better.
Also, it seems that this thesis' approach is able to capture group dynamics broadly.
This could be seen as a first step towards accurately parametrizing paintings with a neural network.


%Verdict
Ultimately, it was indeed possible to generate a brushstroke parametrization for images of paintings.
Although it was not possible to achieve this with a feed-forward approach, the subsequent optimization-based approach still fares well against state-of-the-art counter-parts.
It could even be argued that such an optimization-based approach scales easier than other approaches and enables high-resolution image sizes.
The image resolution of up to one megapixel is especially noteworthy and probably a key factor in generating such detailed renderings.
%%goal achieved?
%%nice image resolution

Surprisingly, the stylization of photographs, which was initially a byproduct of the approach, gave relatively good results.
It could be argued that it is comparable in quality to the best approaches as of mid-2020.
%%is probably a state of the art painterly rendering approach in terms of quality
The other actual goal of generating accurate brushstroke representations of images has not been quite so successful.
The comparison to brushstroke extraction algorithms showed that brushstrokes are not captured as accurately as hoped.
Especially when comparing the details to the original paintings, it becomes evident that the rendered brushstrokes still look significantly different.
Thus the results seem relatively appealing from afar, but less so when getting closer.

It raises the question of whether the extensive work that went into the renderer was worth it.
It seems that the goal of generating real-looking brushstrokes may clash with having a versatile and more efficient renderer.
Future approaches should definitely ask whether the renderer should focus even more on realism or rather tend towards a more simplistic approach. 
%was it worth putting that much effort into the renderer?
This is maybe also a question which could have been dealt with in the course of this thesis.
Other ways could have been thought of, how brushstrokes are parameterized, and it would have been interesting which differences it had made.
%more testing with regard to the brushstrokes could have been performed
%Other approaches to the brushstroke renderer, use paths instead of predefined and paired samples

Another aspect would have been testing different optimizers (\eg L-BGFS) besides the standard AdaM-optimizer.
%different optimizers should have been tested (L-BGFS)

At last, the question arises whether this work will be relevant for the future.
As artistic style transfer is more of a niche than a mainstream field in computer vision, it seems at first as if there is little relevance in this work.
Nevertheless, it was possible to show that state-of-the-art results in painterly rendering can be achieved by employing an approach that could be called dated.
Also, it is imaginable that the resulting brushstroke parametrization could be used for other purposes, such as style transfer on a brushstroke level.
%Is this something that will be used in the future? / relevance?
% parametrized representation is interesting for GNNs and other emerging techniques.
Other possible improvements and future ideas based on this thesis will be explained in the next chapter.

All-in-all, the results are two-faced.
Stylization works reasonably well, but parametrizing paintings leaves much to wish for.
Still, the approach and its results could be seen as a proof-of-concept for simple optimization-based approximation.

