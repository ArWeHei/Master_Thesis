Ongoing research in art-related computer vision has led to impressive results in recent years.
Especially neural style transfer~\cite{gatys} and subsequent work has helped shape computer vision as a field.\\
However, most state-of-the-art approaches are pixel and filter-based and thereby omit the three-dimensional nature of paintings.
This thesis suggests an approach that extracts brushstroke information from images of paintings by reconstructing the paintings with brushstrokes.
The approach is based on a differentiable renderer, which allows to optimize brushstroke parameters directly through backpropagation and gradient descent.
Applying the same approach to photographs allows stylization of these photographs as paintings.\\
The results for the proposed approach are mixed.
Although it falls short of accurately extracting brushstrokes from paintings, it conserves group dynamics in these brushstrokes.
In contrast, stylization is on the same level as state-of-the-art painterly rendering approaches.
